{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X5yC5CkKdHS6"
   },
   "source": [
    "In NLP latest architecture is Transformer based architectures There's three types. Encoder-only models like BERT, decoder-only models like GPT and llama. There's encoder-decoder architectures as well: Encoder-decoder models can be implemented using various neural network architectures, and their names often reflect the type of network used or the specific application. Here are some key examples:\n",
    "1. Transformer-based Encoder-Decoder Models:\n",
    "These models are based on the Transformer architecture, which has significantly advanced the field of natural language processing.\n",
    "T5 (Text-to-Text Transfer Transformer): T5 is a Transformer-based encoder-decoder model that treats all NLP tasks as text-to-text problems. It's widely used for tasks like machine translation, summarization, and question answering.\n",
    "BART (Bidirectional and Auto-Regressive Transformer): BART is another Transformer-based encoder-decoder model that excels at denoising sequence-to-sequence tasks. It's particularly effective for text generation and summarization.\n",
    "Pegasus (Pre-training with Extracted Gap-sentences for Abstractive Summarization): Pegasus is a Transformer-based encoder-decoder model specifically designed for abstractive summarization, where it generates summaries by focusing on key sentences extracted from the input text.\n",
    "MT5 (Massively Multilingual Text-to-Text Transformer): MT5 is a multilingual variant of T5, trained on a large corpus of text in various languages.\n",
    "FLAN-T5 (Scaling Instruction-Finetuned Language Models): FLAN-T5 is an extension of T5 that has been finetuned on a wide range of tasks and instructions to improve its generalization capabilities.\n",
    "Code-T5: This is a variant of T5 designed specifically for code understanding and generation.\n",
    "UL2 (Unifying Language Learning Paradigms): UL2 is another Transformer-based encoder-decoder model with a unified approach to language learning.\n",
    "FLAN-UL2: This is a finetuned version of UL2 with improved performance on various tasks.\n",
    "EdgeFormer: A Transformer-based encoder-decoder model designed for efficient seq2seq generation on devices with limited resources.\n",
    "2. Models Utilizing Encoder-Decoder Architecture for Specific Tasks:\n",
    "Encoder-decoder architectures can also be used as components within larger models designed for specific tasks:\n",
    "VisionEncoderDecoderModel: This model initializes an image-to-text model with a pretrained vision model (like ViT) as the encoder and a pretrained language model (like BERT or GPT2) as the decoder. This allows it to perform tasks like image captioning and optical character recognition (OCR).\n",
    "TrOCR (Transformer-based Optical Character Recognition): TrOCR is a specific instance of the VisionEncoderDecoderModel architecture, fine-tuned for OCR.\n",
    "Note: Encoder-decoder architecture is a framework, and specific implementations can vary in their internal network structure (RNN, CNN, Transformer) and pre-training objectives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iNQ56g1Dgfir"
   },
   "source": [
    "LangChain can be used for app development. Web-side of app development is still done with FastAPI. If you want to include agents then Langgraph is used. Fine-tuning of the model for best hyperparameters can be done using LoRA or QLoRA. LoRA is where memory is a constraint but want to maintain high precision. QLoRA (quantized lora) is used to optimize memory efficiency in comprise for a minimal loss in performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gOPJSz6vAtKH"
   },
   "source": [
    "Llama 2 and 3 and mistral ai were attempted but did not work with system ram and gpu usage constraints. Tiny Llama was finally leveraged on a dataset that contained two columns: one with a full clinical note and the other with the summary written by a healthcare provider. The llm was given the task to summarize a given synthetic clinical note by chatgpt4. The result was an accurate response with extra unnecessary details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5EfIxX6Yhj6n",
    "outputId": "61f94d35-c99a-445a-d011-a879740ad527"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement triton==2.1.0 (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for triton==2.1.0\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install triton==2.1.0 bitsandbytes==0.41.0 peft==0.7.0 transformers==4.38.2 accelerate==0.30.0 trl==0.4.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cuX8cXKJdQS_",
    "outputId": "0741a882-52e4-4d36-e5ca-9856b8abd909"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (0.36.0)\n",
      "Requirement already satisfied: filelock in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from huggingface_hub) (3.20.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from huggingface_hub) (2025.12.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from huggingface_hub) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from huggingface_hub) (6.0.3)\n",
      "Requirement already satisfied: requests in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from huggingface_hub) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from huggingface_hub) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from huggingface_hub) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from requests->huggingface_hub) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from requests->huggingface_hub) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from requests->huggingface_hub) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from requests->huggingface_hub) (2025.11.12)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: numpy in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (2.3.5)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub\n",
    "!pip install numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting peft\n",
      "  Downloading peft-0.18.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from peft) (2.3.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from peft) (24.2)\n",
      "Requirement already satisfied: psutil in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from peft) (7.1.3)\n",
      "Requirement already satisfied: pyyaml in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from peft) (6.0.3)\n",
      "Requirement already satisfied: torch>=1.13.0 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from peft) (2.9.1)\n",
      "Requirement already satisfied: transformers in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from peft) (4.57.3)\n",
      "Requirement already satisfied: tqdm in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from peft) (4.67.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from peft) (1.12.0)\n",
      "Requirement already satisfied: safetensors in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from peft) (0.7.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from peft) (0.36.0)\n",
      "Requirement already satisfied: filelock in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from huggingface_hub>=0.25.0->peft) (3.20.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from huggingface_hub>=0.25.0->peft) (2025.10.0)\n",
      "Requirement already satisfied: requests in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from huggingface_hub>=0.25.0->peft) (2.32.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from huggingface_hub>=0.25.0->peft) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from huggingface_hub>=0.25.0->peft) (1.2.0)\n",
      "Requirement already satisfied: setuptools in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (3.1.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from transformers->peft) (2025.11.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from transformers->peft) (0.22.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from jinja2->torch>=1.13.0->peft) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from requests->huggingface_hub>=0.25.0->peft) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from requests->huggingface_hub>=0.25.0->peft) (2025.11.12)\n",
      "Downloading peft-0.18.0-py3-none-any.whl (556 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m556.4/556.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: peft\n",
      "Successfully installed peft-0.18.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6FSQj94TEHtB",
    "outputId": "04f9d218-215f-432b-e770-5bf6faaa65f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: trl in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (0.26.2)\n",
      "Requirement already satisfied: accelerate>=1.4.0 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from trl) (1.12.0)\n",
      "Requirement already satisfied: datasets>=3.0.0 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from trl) (4.4.1)\n",
      "Requirement already satisfied: transformers>=4.56.1 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from trl) (4.57.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from accelerate>=1.4.0->trl) (2.3.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from accelerate>=1.4.0->trl) (24.2)\n",
      "Requirement already satisfied: psutil in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from accelerate>=1.4.0->trl) (7.1.3)\n",
      "Requirement already satisfied: pyyaml in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from accelerate>=1.4.0->trl) (6.0.3)\n",
      "Requirement already satisfied: torch>=2.0.0 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from accelerate>=1.4.0->trl) (2.9.1)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from accelerate>=1.4.0->trl) (0.36.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from accelerate>=1.4.0->trl) (0.7.0)\n",
      "Requirement already satisfied: filelock in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from datasets>=3.0.0->trl) (3.20.1)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from datasets>=3.0.0->trl) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from datasets>=3.0.0->trl) (0.4.0)\n",
      "Requirement already satisfied: pandas in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from datasets>=3.0.0->trl) (2.3.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from datasets>=3.0.0->trl) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from datasets>=3.0.0->trl) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from datasets>=3.0.0->trl) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from datasets>=3.0.0->trl) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from datasets>=3.0.0->trl) (0.70.18)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=3.0.0->trl) (2025.10.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from transformers>=4.56.1->trl) (2025.11.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from transformers>=4.56.1->trl) (0.22.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=3.0.0->trl) (3.13.2)\n",
      "Requirement already satisfied: anyio in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from httpx<1.0.0->datasets>=3.0.0->trl) (4.12.0)\n",
      "Requirement already satisfied: certifi in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from httpx<1.0.0->datasets>=3.0.0->trl) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from httpx<1.0.0->datasets>=3.0.0->trl) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from httpx<1.0.0->datasets>=3.0.0->trl) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0->datasets>=3.0.0->trl) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from huggingface_hub>=0.21.0->accelerate>=1.4.0->trl) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from huggingface_hub>=0.21.0->accelerate>=1.4.0->trl) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2.3.0)\n",
      "Requirement already satisfied: setuptools in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.1.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from pandas->datasets>=3.0.0->trl) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from pandas->datasets>=3.0.0->trl) (2025.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=3.0.0->trl) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=3.0.0->trl) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=3.0.0->trl) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=3.0.0->trl) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=3.0.0->trl) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=3.0.0->trl) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=3.0.0->trl) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate>=1.4.0->trl) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from jinja2->torch>=2.0.0->accelerate>=1.4.0->trl) (3.0.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!pip install triton\n",
    "!pip install trl\n",
    "import torch\n",
    "from transformers import (AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments, pipeline)\n",
    "from transformers.generation import LogitsProcessorList, TopKLogitsWarper, TopPLogitsWarper\n",
    "from trl import SFTTrainer\n",
    "from peft import LoraConfig\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RDuLBdmZP4PB"
   },
   "source": [
    "Llama model requires too much system ram and is crashing which is the reason for using tiny llama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235,
     "referenced_widgets": [
      "d6ab80423f604f4bae8aa46a4797e4ca",
      "537a5871d0454ac981ad8ec2805e2de8",
      "8fb49fab035949a59569862606c49a22",
      "7579a2be776e466ca9a4af9ae4b662a7",
      "eeb02968c7694eea8953eacc839d3dad",
      "a72af26bfbd243f8b65142d984979682",
      "81c0648995c54d0faf7acd0da84d96cf",
      "aeca22593a13484fab8d17c2db8d2df1",
      "a534fd8cc06941988b203a0c7018dd65",
      "e7a0241728194427a19c5994e2090f37",
      "cc5980f3e5dc49e883773383563f19a8",
      "fdccff9caf504371b487c6e93dbc8659",
      "a738ae1399234b549b8305e75442371c",
      "c5885b0e173c4463be73901b14695300",
      "911191c88d0d47eeb8316056a1042aae",
      "a15263272c37473a9474bb305d32fb20",
      "e4ead51755124128b609755333f9a092",
      "9a18742e18a14bf7a1e8d99383f9e0c8",
      "801f3048a45d41cdaad19e1f2051f41e",
      "772b58eb7585470184b037437e7a70c5",
      "cf420480934f4132ac26d9301a4a0130",
      "bce00b81a6f541e681f1c7b05f457287",
      "ee97074329b44aef8210b517302ac625",
      "9319554c4c1f40cba3ba76e40d1b6be0",
      "d059c113056d4821af5f222c6a391133",
      "a84f01ffc29947a287ad99bbf2b4a0e2",
      "4f7e358d332249319497afe829014687",
      "bf161e2750444f32bc5292f0215df4e4",
      "e69c0bf5efa2497c8043e6aba9a56060",
      "b0647ed504204312bddaec1ba1c96d48",
      "8247ab056e61438d92741cd07d98c2b8",
      "3e8b10bc3c614a77aab2e66c88afddcc",
      "826af569ffa448078035dc41f8cc719b"
     ]
    },
    "id": "fjhMjwB-mgWE",
    "outputId": "655f178b-b8b3-41ad-dfac-b24a8ff3550d"
   },
   "outputs": [],
   "source": [
    "llama_model = AutoModelForCausalLM.from_pretrained(\n",
    "    pretrained_model_name_or_path=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
    "    # Remove quantization_config\n",
    ").to('cpu') # Explicitly move the model to CPU\n",
    "llama_model.config.use_cache = False\n",
    "llama_model.config.pretraining_tp = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mJxdpp7Qmh9x"
   },
   "source": [
    "The below code is specifically for GPU. Bitsandbytes config with quantization is for gpu. The above code is for CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xS_u1rJlovR_"
   },
   "outputs": [],
   "source": [
    "###llama_model = AutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path= \"aboonaji/llama2finetune-v3\",\n",
    "                                                  # quantization_config= BitsAndBytesConfig(load_in_4bit = True,\n",
    "                                                   # bnb_4bit_compute_dtype = getattr(torch, \"float16\"), bnb_4bit_quant_type = \"nf4\"))\n",
    "##llama_model.config.use_cache = False\n",
    "##llama_model.config.pretraining_tp = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "0a25fb841a5c4c328dac1663ed596ad1",
      "8ab8336697dc40c78c0e9c5ab39de4f5",
      "785e3d33b18740c1bd0f5dc00485771c",
      "512ecc844c5c492a9105ae89ff28d762",
      "a750bce01b7f4bbc8fb179c1d6dec202",
      "10a8e1f14d7841108ba7ab32fe6cf323",
      "0d084f8ec2024580a961924baaadd7fe",
      "a27d631f3e6b4305b61f4e477424ce4e",
      "5dbc66948a604fee8fc481dc1d3fe9b8",
      "3e713f811a0849238ed7afaaddc1d10b",
      "2e668fec9a5b43e38bf0b8bd3a98925a",
      "1281a4fbba504f70adb944a6fb6e69b0",
      "139f4f68431949bfac2ddec0bf04a69d",
      "dfee16ad133140e4853acd53a2e1cc4c",
      "e3789fc1a94f4cf2944bc16de8911030",
      "a6442513e92041f89c657af7a918890b",
      "41a150f35dfd41faaa057b9f9a9eac65",
      "0f4d333f2e0e46e5bb657c39aa5f0829",
      "52b1812d057b4710b2af566ffca3ecf4",
      "a398a197c4624edcb14a5c3f7029f7de",
      "2be0c51229ee48b1a7fdb59d7afdff0d",
      "7554e5b6af624d70aadad578eb9ab4c4",
      "7501a9406a02496893864d8cc501e296",
      "8e3f0c3e936d4ba795cf6ce3a51e9c17",
      "536fc921d3354886a036f06d84d4ab3a",
      "e49be9fbb2ac47c2b953e06fb4503bf4",
      "376d584fa00344ad9ed79a0e80a9cbbe",
      "623651732772439a9c1c63376be2e4ac",
      "e6b83ddbdcf44d7b9cb0d651fc9fbdec",
      "92b2f872cb624f23b4c2eaf5aa29a4e3",
      "592cc42a7dc142f4bd77d01932133ca2",
      "a5abe5bd54b74b4eb76347d2fad43ccd",
      "422f1aaa73a0445ab899240277c6b072",
      "d844dcc7d6574723828e81981a3f63fd",
      "3178d1cafd3646dfa08bef1f73d5883d",
      "f0bbf3ec760f4932825e9119fa22bf1f",
      "1f29a3335d5644038aaaa22f9a17699d",
      "a5c339d3541b4d9b8667268d14dabeb5",
      "f9a0c472bb804c9ba1c01e6e2aff1102",
      "04d81c6337114b06901f352c76fdd59b",
      "48426f2f6e0c49daa8629dec939aacb8",
      "8d37d394f68d46debfcecca59ed22b95",
      "0413e3e5c9f74528b5108f7cd64b3490",
      "b36d4e0e5ef940be8f6783ec554814d2"
     ]
    },
    "id": "GnL0E6_L210P",
    "outputId": "94d25383-242e-4d2a-ef9a-f348effdf8e1"
   },
   "outputs": [],
   "source": [
    "llama_tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path= \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\", trust_remote_code = True)\n",
    "llama_tokenizer.pad_token = llama_tokenizer.eos_token\n",
    "llama_tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "hb6Wrg0V5H-E"
   },
   "outputs": [],
   "source": [
    "training_arguments = TrainingArguments(output_dir= \"./results\", per_device_train_batch_size = 1, max_steps = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "97fecc086a524176bccb1028573c8f0b",
      "af87e98125f5466c8d891033fa82ef58",
      "161e9bb869e044b0aff5f87af25fe6fa",
      "edaf9e72ed8b4e7a92842a51121335f7",
      "ae2e47adf2584db9aaf86e355c5591e2",
      "3dedbea8b3c640a9b8fd6d84a662bd8c",
      "6b018d12cb4b4bb49374d2b81638bc3a",
      "a302dd8ac7084b409578a90ea294622f",
      "bc0c4ae63c4345f4ad722ab4fff557fd",
      "867526f5b7914accb07b402ccdb8180c",
      "aa6a3a174cdc4534a58a5a28f67d0adf",
      "b8635dceb9f74e7dbbf317c7a7e15259",
      "b19bc018851a4c4bbd4632189d8db8bc",
      "f81e281e18f84779b7d71db095451e5b",
      "2110f2fefe3e4ccca1e06791cca82bfb",
      "d3a96087bde646c1add80cdcb29210c4",
      "bd88a76ddb06428e883a53ad6d4ea112",
      "ef268e08da9745ab900bd0669bc750da",
      "10aa350f9ee24c8a97f91d1a69b477dc",
      "2f07871ae33349c0b5dfbce085df3fb3",
      "99e7fc93839b4b34939a9af369d9766d",
      "c69feb220d0549a8a74d3f89f330c830"
     ]
    },
    "id": "iqyz670MRRsH",
    "outputId": "3502b422-64d2-417a-ac7d-3f44ed3e1098"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (4.4.1)\n",
      "Requirement already satisfied: huggingface_hub in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (0.36.0)\n",
      "Collecting huggingface_hub\n",
      "  Using cached huggingface_hub-1.2.3-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: fsspec in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (2025.10.0)\n",
      "Collecting fsspec\n",
      "  Using cached fsspec-2025.12.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: filelock in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from datasets) (3.20.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from datasets) (2.3.5)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: packaging in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from huggingface_hub) (1.2.0)\n",
      "Requirement already satisfied: shellingham in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from huggingface_hub) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from huggingface_hub) (0.20.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from huggingface_hub) (4.15.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: anyio in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (4.12.0)\n",
      "Requirement already satisfied: certifi in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from pandas->datasets) (2025.3)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from typer-slim->huggingface_hub) (8.3.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Using cached huggingface_hub-1.2.3-py3-none-any.whl (520 kB)\n",
      "Installing collected packages: huggingface_hub\n",
      "  Attempting uninstall: huggingface_hub\n",
      "    Found existing installation: huggingface-hub 0.36.0\n",
      "    Uninstalling huggingface-hub-0.36.0:\n",
      "      Successfully uninstalled huggingface-hub-0.36.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "transformers 4.57.3 requires huggingface-hub<1.0,>=0.34.0, but you have huggingface-hub 1.2.3 which is incompatible.\n",
      "langchain-huggingface 1.2.0 requires huggingface-hub<1.0.0,>=0.33.4, but you have huggingface-hub 1.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed huggingface_hub-1.2.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 19756/19756 [00:00<00:00, 90022.13 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function load_dataset at 0x13291e700>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install -U datasets huggingface_hub fsspec\n",
    "\n",
    "\n",
    "load_dataset(\"geekdom/clinical_data\")\n",
    "print(load_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86,
     "referenced_widgets": [
      "f4eef9df157d4438a89c919fd8709261",
      "ba1ef26ca14343b295aa0a34b2698b5d",
      "984047c1e4e44850851ced7e8bb22c39",
      "e203a9bc0719403285bacf2878703514",
      "d75405a898bd4184a4ea9349f5296c80",
      "c305def1b3d540bf8b214e9f95199078",
      "7a8bd5f756a34f5dbf25aec399954b92",
      "ed73110330554347a8256c0b3560f2c2",
      "3846daaecdf244208f0caf131b6d050d",
      "15aba5daec9848bb8576f9679b4b1ff7",
      "6ae6bbd922d8496da93fc18952adf71c"
     ]
    },
    "id": "iFEzORxVwunD",
    "outputId": "66cc0905-e3c4-42de-e126-7034d81270eb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 19756/19756 [00:02<00:00, 7380.32 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(\"geekdom/clinical_data\", split=\"train\")\n",
    "\n",
    "# Format for SFT / text-to-text\n",
    "def format_for_sft(example):\n",
    "    return {\n",
    "        \"text\": f\"Summarize:\\n{example['prompt']}\\n\\nSummary: {example['response']}\"\n",
    "    }\n",
    "\n",
    "dataset = dataset.map(format_for_sft)\n",
    "\n",
    "# Keep only the 'text' column\n",
    "dataset = dataset.remove_columns([col for col in dataset.column_names if col != \"text\"])\n",
    "\n",
    "# Load tokenizer for your model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")  # replace with your LLaMA path\n",
    "\n",
    "# Tokenize dataset\n",
    "def tokenize_fn(example):\n",
    "    return tokenizer(example[\"text\"], truncation=True, padding=\"max_length\", max_length=512)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_fn, batched=True)\n",
    "tokenized_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 19756\n",
       "})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: peft in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (0.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from peft) (2.3.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from peft) (24.2)\n",
      "Requirement already satisfied: psutil in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from peft) (7.1.3)\n",
      "Requirement already satisfied: pyyaml in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from peft) (6.0.3)\n",
      "Requirement already satisfied: torch>=1.13.0 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from peft) (2.9.1)\n",
      "Requirement already satisfied: transformers in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from peft) (4.57.3)\n",
      "Requirement already satisfied: tqdm in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from peft) (4.67.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from peft) (1.12.0)\n",
      "Requirement already satisfied: safetensors in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from peft) (0.7.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from peft) (1.2.3)\n",
      "Requirement already satisfied: filelock in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from huggingface_hub>=0.25.0->peft) (3.20.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from huggingface_hub>=0.25.0->peft) (2025.10.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from huggingface_hub>=0.25.0->peft) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from huggingface_hub>=0.25.0->peft) (0.28.1)\n",
      "Requirement already satisfied: shellingham in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from huggingface_hub>=0.25.0->peft) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from huggingface_hub>=0.25.0->peft) (0.20.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from huggingface_hub>=0.25.0->peft) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (3.1.6)\n",
      "Collecting huggingface_hub>=0.25.0 (from peft)\n",
      "  Using cached huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from transformers->peft) (2025.11.3)\n",
      "Requirement already satisfied: requests in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from transformers->peft) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from transformers->peft) (0.22.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from jinja2->torch>=1.13.0->peft) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from requests->transformers->peft) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from requests->transformers->peft) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from requests->transformers->peft) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from requests->transformers->peft) (2025.11.12)\n",
      "Requirement already satisfied: anyio in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.25.0->peft) (4.12.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.25.0->peft) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub>=0.25.0->peft) (0.16.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from typer-slim->huggingface_hub>=0.25.0->peft) (8.3.1)\n",
      "Using cached huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "Installing collected packages: huggingface_hub\n",
      "  Attempting uninstall: huggingface_hub\n",
      "    Found existing installation: huggingface_hub 1.2.3\n",
      "    Uninstalling huggingface_hub-1.2.3:\n",
      "      Successfully uninstalled huggingface_hub-1.2.3\n",
      "Successfully installed huggingface_hub-0.36.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "a840246ebd884fc3b29ed1658b97f0d7",
      "63509b1c0c09414ebaf1ff0368850c4d",
      "d4ad1588c3f840eeae3975596be57789",
      "1cf15474724c4fa88ffe87e4131fd7d6",
      "c47be9df94df41ecbb3bbefee930b288",
      "9b55ea73973e40f5899bea33d24434fd",
      "e9cbae1b5ec74df2983fe6317fd510cb",
      "883e019f290b43069bfc266e11a363e8",
      "1768a5e6c1f642a4b654f3d9efb5db12",
      "458a3ebd69274c47afa1da9203dbd193",
      "1ed5102319084bfcb10c72228d14ae03",
      "2e6810f37ec5425f9bffa14b8fe43e0a",
      "5b7c0e06e0574cc3a4cd57ad1a372bd4",
      "470a45ee533740b5b7ba098dc3880476",
      "26a9cc80a30946ffb410bd6406ba553b",
      "6f41ad23408d462ba295c2d62999fc19",
      "c2a8a3f133eb4a3e88fc5f233dd4a1c3",
      "e6dbbf7d6a0d4681a0111a165f778b5c",
      "ee8af418549844f0a3ddd3f71f0ddc79",
      "ad3030bfe0174f138c32e4bf0d1726a4",
      "a2067a1c27254f65bdf2ea7637747760",
      "266497822ae74c1898c011120453f94f",
      "d0c6b8d0bb8d4ce59b75ae370a7f8cbf",
      "3bfd7bfb61764fa5bf46e75454d9378d",
      "077cc1e2a1e3488b9cb89b52edcaf55c",
      "b21734eebc38433c86febfb0c2222046",
      "16e5b0e28cd34bd08360b9c8cd9472d9",
      "29c80e6e02594c9d8215d923cf71c3c3",
      "0717f7fba2de48b3828957c734d16ee3",
      "d76f2bb718df419d9afbdaf37d5cea5b",
      "97ea1cde14bf499e907f356c5fed2a02",
      "54af06c1c62349479e7f5a24944af005",
      "066f7300a9a4414cb2479dd51625fdcd"
     ]
    },
    "id": "wLsK4lfx7sPi",
    "outputId": "8afb2b50-3406-42e9-f1fb-835736892c8c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 19756/19756 [00:00<00:00, 84667.96 examples/s]\n",
      "/var/folders/ht/stt2pwyj30nd38vj2cm2nbzc0000gn/T/ipykernel_21439/4241640021.py:17: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, DataCollatorForLanguageModeling\n",
    "\n",
    "# Use a data collator for causal language modeling\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False  # Set False for causal LM\n",
    ")\n",
    "\n",
    "# Make labels same as input_ids for causal LM\n",
    "def add_labels(batch):\n",
    "    batch[\"labels\"] = batch[\"input_ids\"].clone()\n",
    "    return batch\n",
    "\n",
    "tokenized_dataset = tokenized_dataset.map(add_labels, batched=True)\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=llama_model,\n",
    "    args=training_arguments,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 2}.\n",
      "/Users/saiashutoshchellarapu/.pyenv/versions/3.12.3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 03:46, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: command buffer exited with error status.\n",
      "\tThe Metal Performance Shaders operations encoded on it may not have completed.\n",
      "\tError: \n",
      "\t(null)\n",
      "\tInsufficient Memory (00000008:kIOGPUCommandBufferCallbackErrorOutOfMemory)\n",
      "\t<AGXG17GFamilyCommandBuffer: 0x7c027d180>\n",
      "    label = <none> \n",
      "    device = <AGXG17GDevice: 0x7d85a0000>\n",
      "        name = Apple M5 \n",
      "    commandQueue = <AGXG17GFamilyCommandQueue: 0x7d85a4000>\n",
      "        label = <none> \n",
      "        device = <AGXG17GDevice: 0x7d85a0000>\n",
      "            name = Apple M5 \n",
      "    retainedReferences = 1\n",
      "Error: command buffer exited with error status.\n",
      "\tThe Metal Performance Shaders operations encoded on it may not have completed.\n",
      "\tError: \n",
      "\t(null)\n",
      "\tInsufficient Memory (00000008:kIOGPUCommandBufferCallbackErrorOutOfMemory)\n",
      "\t<AGXG17GFamilyCommandBuffer: 0x7bf6d3b80>\n",
      "    label = <none> \n",
      "    device = <AGXG17GDevice: 0x7d85a0000>\n",
      "        name = Apple M5 \n",
      "    commandQueue = <AGXG17GFamilyCommandQueue: 0x7d85a4000>\n",
      "        label = <none> \n",
      "        device = <AGXG17GDevice: 0x7d85a0000>\n",
      "            name = Apple M5 \n",
      "    retainedReferences = 1\n",
      "Error: command buffer exited with error status.\n",
      "\tThe Metal Performance Shaders operations encoded on it may not have completed.\n",
      "\tError: \n",
      "\t(null)\n",
      "\tInsufficient Memory (00000008:kIOGPUCommandBufferCallbackErrorOutOfMemory)\n",
      "\t<AGXG17GFamilyCommandBuffer: 0x7bf6d3b80>\n",
      "    label = <none> \n",
      "    device = <AGXG17GDevice: 0x7d85a0000>\n",
      "        name = Apple M5 \n",
      "    commandQueue = <AGXG17GFamilyCommandQueue: 0x7d85a4000>\n",
      "        label = <none> \n",
      "        device = <AGXG17GDevice: 0x7d85a0000>\n",
      "            name = Apple M5 \n",
      "    retainedReferences = 1\n",
      "Error: command buffer exited with error status.\n",
      "\tThe Metal Performance Shaders operations encoded on it may not have completed.\n",
      "\tError: \n",
      "\t(null)\n",
      "\tInsufficient Memory (00000008:kIOGPUCommandBufferCallbackErrorOutOfMemory)\n",
      "\t<AGXG17GFamilyCommandBuffer: 0x7bf6c4700>\n",
      "    label = <none> \n",
      "    device = <AGXG17GDevice: 0x7d85a0000>\n",
      "        name = Apple M5 \n",
      "    commandQueue = <AGXG17GFamilyCommandQueue: 0x7d85a4000>\n",
      "        label = <none> \n",
      "        device = <AGXG17GDevice: 0x7d85a0000>\n",
      "            name = Apple M5 \n",
      "    retainedReferences = 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4, training_loss=0.9194257259368896, metrics={'train_runtime': 230.5088, 'train_samples_per_second': 0.017, 'train_steps_per_second': 0.017, 'total_flos': 12712088174592.0, 'train_loss': 0.9194257259368896, 'epoch': 0.00020247013565499088})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lu_7zKlBwjh0",
    "outputId": "41e4d28d-391b-4cca-a437-873f8a6620e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "    Make sure to use line breaks when appropriate.\n",
      "\n",
      "    ### Instruction:\n",
      "\n",
      "    Below is a clinical note.\n",
      "\n",
      "    Your task is to summarize the clinical note in that you describe the patient's course of progression.\n",
      "\n",
      "    ### Input:\n",
      "\n",
      "    Hospital Course: The patient was admitted to the ICU six days after testing positive for COVID-19 due to worsening respiratory distress.\n",
      "\n",
      "    Early physical therapy and prone positioning led to improved oxygen saturation from 85% to 94%. After five days of supportive care and rehabilitation,\n",
      "\n",
      "    the patient was transferred to the general ward and continued progressing with assisted ambulation and breathing exercises.\n",
      "\n",
      "    Discharge Condition: At discharge, the patient was stable, breathing comfortably on room air, and able to walk short distances with minimal assistance.\n",
      "\n",
      "    Oxygen saturation and respiratory rate were within normal limits.\n",
      "\n",
      "    ### Response:\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Select device: MPS if available, else CPU\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "llama_model.to(device)\n",
    "\n",
    "user_prompt = (\n",
    "    \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\n",
    "    Make sure to use line breaks when appropriate.\\n\n",
    "    ### Instruction:\\n\n",
    "    Below is a clinical note.\\n\n",
    "    Your task is to summarize the clinical note in that you describe the patient's course of progression.\\n\n",
    "    ### Input:\\n\n",
    "    Hospital Course: The patient was admitted to the ICU six days after testing positive for COVID-19 due to worsening respiratory distress.\\n\n",
    "    Early physical therapy and prone positioning led to improved oxygen saturation from 85% to 94%. After five days of supportive care and rehabilitation,\\n\n",
    "    the patient was transferred to the general ward and continued progressing with assisted ambulation and breathing exercises.\\n\n",
    "    Discharge Condition: At discharge, the patient was stable, breathing comfortably on room air, and able to walk short distances with minimal assistance.\\n\n",
    "    Oxygen saturation and respiratory rate were within normal limits.\\n\n",
    "    ### Response:\"\"\"\n",
    ")\n",
    "\n",
    "# Tokenize and move inputs to same device\n",
    "inputs = llama_tokenizer(user_prompt, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "# Move model to float32 to avoid NaNs on MPS\n",
    "llama_model = llama_model.to(torch.float32)\n",
    "\n",
    "# Disable sampling to avoid NaNs (use greedy generation)\n",
    "with torch.no_grad():\n",
    "    outputs = llama_model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=200,\n",
    "        do_sample=False,  # <--- Important: Greedy avoids NaNs\n",
    "        temperature=1.0,  # ignored with do_sample=False\n",
    "        top_p=1.0,        # ignored with do_sample=False\n",
    "        pad_token_id=llama_tokenizer.pad_token_id\n",
    "    )\n",
    "\n",
    "# Decode output\n",
    "response = llama_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-3pLFzsFxB5P"
   },
   "source": [
    "# Result:\n",
    "\n",
    "Below is the input given to the model. The model produces a decent answer but the answer depends exremely on the instructions given. The answer is accurate but lacks precision because extra details before or after the response are sometimes given. The response is unique each generation of response.\n",
    "\n",
    "# Given Input\n",
    "\n",
    "Hospital Course:\n",
    "\n",
    "The patient was admitted to the ICU six days after testing positive for COVID-19 due to worsening respiratory distress. Early physical therapy and prone positioning led to improved oxygen saturation from 85% to 94%. After five days of supportive care and rehabilitation, the patient was transferred to the general ward and continued progressing with assisted ambulation and breathing exercises.\n",
    "\n",
    "Discharge Condition:\n",
    "\n",
    "At discharge, the patient was stable, breathing comfortably on room air, and able to walk short distances with minimal assistance. Oxygen saturation and respiratory rate were within normal limits."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "3.12.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
